{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "397a515f-c8d7-477f-8776-bfec3db6428f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import mlflow as mf \n",
    "import joblib\n",
    "import torch\n",
    "import transformers\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import ftzard.utils.mlflow as mf_utils\n",
    "\n",
    "\n",
    "from hydra import initialize, compose\n",
    "from warnings import filterwarnings\n",
    "\n",
    "from transformers import DataCollatorWithPadding, AutoTokenizer\n",
    "import dagstermill as dgm\n",
    "from ftzard.utils.common import get_current_date_time\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef3c9363-e24b-48ff-a9f8-f270226a2b1a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symlink already created...\n"
     ]
    }
   ],
   "source": [
    "base_path = '/app/ftzard'\n",
    "config_path = f'{base_path}/config/'\n",
    "try:\n",
    "    os.symlink(config_path, \"config_link\")\n",
    "except Exception as e:\n",
    "    print(\"Symlink already created...\")\n",
    "config_name = 'config'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5350cc18-298a-4b31-8e7e-df8dd2825035",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with initialize(version_base=None, config_path=\"config_link\"):\n",
    "    cfg = compose(config_name=config_name)\n",
    "    tracking_uri, experiment_name = cfg.MLFLOW.TRACKING.URI, cfg.MLFLOW.EXPERIMENT.NAME\n",
    "    mlflow_model_name = cfg.MLFLOW.MODEL.NAME \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b1bef06-2bde-4760-957d-4e238ebcb52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Run Name: INFERENCE\n",
      "Mlflow Experiment Name:  senetiment_analysis\n",
      "Mlflow Run Name:  2024-07-02_11:54\n",
      "Mlflow Model Name:  FalconSentiAnalysis\n",
      "Mlflow Model Alias:  champion\n"
     ]
    }
   ],
   "source": [
    "os.environ['MLFLOW_TRACKING_URI'] = tracking_uri\n",
    "run_name = get_current_date_time()\n",
    "base_run_name = \"INFERENCE\"\n",
    "alias = 'champion'\n",
    "print(\"Base Run Name:\", base_run_name)\n",
    "print('Mlflow Experiment Name: ', experiment_name)\n",
    "print('Mlflow Run Name: ', run_name)\n",
    "print('Mlflow Model Name: ', mlflow_model_name)\n",
    "print(\"Mlflow Model Alias: \", alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d200b1a9-19bc-4ab5-be06-d59b4217a7a4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.0.1 available.\n"
     ]
    }
   ],
   "source": [
    "datasets = joblib.load(f\"{base_path}/data/tokenized_dataset.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb2043ae-e7fc-49c2-96c1-35a2b8d0656c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets = datasets[\"datasets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c49644c0-1b1c-4cca-b50b-b59580fced07",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['label', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 480\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(datasets['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dbecedb-eecf-4a39-9b70-4882885a9fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:alembic.runtime.migration:Context impl SQLiteImpl.\n",
      "INFO:alembic.runtime.migration:Will assume non-transactional DDL.\n",
      "2024/07/02 11:54:23 INFO mlflow.transformers: 'models:/FalconSentiAnalysis@champion' resolved as '/app/ftzard/pipeline/notebooks/mlruns/1/9953da46234843f1a475e042a89a9b2c/artifacts'\n",
      "Loading checkpoint shards: 100%|████████████████████████████████████████████| 2/2 [00:13<00:00,  6.99s/it]\n",
      "Some weights of FalconForSequenceClassification were not initialized from the model checkpoint at tiiuae/falcon-7b and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "## Load Model ##\n",
    "model_uri = f\"models:/{mlflow_model_name}@{alias}\"\n",
    "components = mf.transformers.load_model(model_uri, return_type=\"components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e1fc937-675b-4b65-8ec6-53b7b2afa1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = components[\"tokenizer\"]\n",
    "model = components[\"model\"]\n",
    "del components\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37643f1e-406f-4f33-9c68-ad764d252f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForSequenceClassification(\n",
      "  (base_model): LoraModel(\n",
      "    (model): FalconForSequenceClassification(\n",
      "      (transformer): FalconModel(\n",
      "        (word_embeddings): Embedding(65024, 4544)\n",
      "        (h): ModuleList(\n",
      "          (0-31): 32 x FalconDecoderLayer(\n",
      "            (self_attention): FalconAttention(\n",
      "              (rotary_emb): FalconRotaryEmbedding()\n",
      "              (query_key_value): lora.Linear(\n",
      "                (base_layer): FalconLinear(in_features=4544, out_features=4672, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05187051351110231, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4544, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4672, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (dense): lora.Linear(\n",
      "                (base_layer): FalconLinear(in_features=4544, out_features=4544, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05187051351110231, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4544, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4544, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (mlp): FalconMLP(\n",
      "              (dense_h_to_4h): lora.Linear(\n",
      "                (base_layer): FalconLinear(in_features=4544, out_features=18176, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05187051351110231, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4544, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=18176, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (act): GELUActivation()\n",
      "              (dense_4h_to_h): lora.Linear(\n",
      "                (base_layer): FalconLinear(in_features=18176, out_features=4544, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05187051351110231, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=18176, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4544, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "            )\n",
      "            (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (ln_f): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (score): ModulesToSaveWrapper(\n",
      "        (original_module): Linear(in_features=4544, out_features=2, bias=False)\n",
      "        (modules_to_save): ModuleDict(\n",
      "          (default): Linear(in_features=4544, out_features=2, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b57ac8ae-e34a-4d16-bc97-fe30904746ba",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided experiment name senetiment_analysis already exists, the run will be logged in this experiment.\n",
      "                                 \n"
     ]
    }
   ],
   "source": [
    "experiment_id = mf_utils.create_experiment(exp_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1b1a4f4-f44e-420f-8a49-d0b52a800df4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device of PEFT MODEL:  cuda:0\n",
      "Getting predictions from best model....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 15/15 [00:06<00:00,  2.39it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "Preparing Data For Evaluation\n",
    "'''\n",
    "eval_dataloader = DataLoader(\n",
    "    datasets[\"test\"],\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    collate_fn=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    ")\n",
    "\n",
    "device = model.device\n",
    "\n",
    "print(\"Device of PEFT MODEL: \", device)\n",
    "\n",
    "def get_predictions(batch):\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    # token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**{\"input_ids\":input_ids, \"attention_mask\":attention_mask})\n",
    "        logits = outputs.logits\n",
    "        predicted_labels = torch.argmax(logits, dim=-1) # Move predicted_labels to the same device\n",
    "\n",
    "    return predicted_labels.cpu().numpy(), logits\n",
    "\n",
    "print('Getting predictions from best model....')\n",
    "\n",
    "\n",
    "base_run_id = mf_utils.get_run_id_by_name(run_name=base_run_name, \n",
    "                                             experiment_ids=[experiment_id])\n",
    "with mf.start_run(run_id=base_run_id, experiment_id=experiment_id):\n",
    "    run_id = mf_utils.get_run_id_by_name(run_name=run_name, \n",
    "                                             experiment_ids=[experiment_id], nested=True)\n",
    "    mf.start_run(run_id=run_id, run_name=run_name, experiment_id=experiment_id,nested=True)\n",
    "    all_predictions, all_logits = [], []\n",
    "    for batch in tqdm(eval_dataloader):\n",
    "        predictions, logits = get_predictions(batch)\n",
    "        all_predictions.extend(predictions)\n",
    "        all_logits.extend(logits)\n",
    "    try:\n",
    "        mf.log_param(\"NumberOfReocrds\", len(all_logits))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    mf.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131c6eb9-c9ca-49e2-8c3a-343a0a5e08ac",
   "metadata": {},
   "source": [
    "## ONLY WHEN YOU HAVE A LABELLED TEST SET (OPTIONAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4710b5c-ef2f-4e24-8996-cef8fb80c6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching true labels from dataset....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 278.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Classification Report         \n",
      "-----------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.82      0.85       240\n",
      "           1       0.83      0.90      0.86       240\n",
      "\n",
      "    accuracy                           0.86       480\n",
      "   macro avg       0.86      0.86      0.86       480\n",
      "weighted avg       0.86      0.86      0.86       480\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# print('Fetching true labels from dataset....')\n",
    "# true = []\n",
    "# for batch in tqdm(eval_dataloader):\n",
    "#     true.extend(batch['labels'])\n",
    "\n",
    "# print('                  Classification Report         ')\n",
    "# print(\"-----------------------------------------------------\")\n",
    "# print(classification_report(true, all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82817abc-270c-48ac-8e9f-da42fc4a9a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with mf.start_run(run_id=base_run_id, run_name=base_run_name, experiment_id=experiment_id):\n",
    "#     with mf.start_run(run_id=run_id, run_name=run_name, experiment_id=experiment_id,\n",
    "#                      nested=True):\n",
    "#         mf.log_metric(\"accuracy\", accuracy_score(true, all_predictions))\n",
    "#         mf.log_metric(\"f1_score\", accuracy_score(true, all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0706a68-cc1a-44e8-83f4-6b5ed37c9a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = {\"data\": datasets[\"test\"],\n",
    "           \"predicted_labels\": all_predictions,\n",
    "          \"logits\": [i.cpu().numpy() for i in all_logits]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64ecf2ef-322c-41a2-ad6b-3940476e5f0d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save_path = f\"{base_path}/data/predictions.joblib\"\n",
    "# with open(save_path, 'wb') as f:\n",
    "#     joblib.dump(outputs, f)\n",
    "metadata = {\"run_name\": run_name,\n",
    "           \"run_id\":run_id,\n",
    "           \"base_run_id\": base_run_id,\n",
    "           \"base_run_name\": base_run_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "075bca8c-3df6-4b8f-ae7a-e02e186d7c1c",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'run_name': '2024-07-02_11:54',\n",
       " 'run_id': 'c02f01049b5a4781b364917430552dc7',\n",
       " 'base_run_id': 'a88ae9eaf69a4ec283168c1507a5bc0b',\n",
       " 'base_run_name': 'INFERENCE'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgm.yield_result(outputs, output_name=\"predictions_logits\")\n",
    "dgm.yield_result(metadata, output_name='step5_run_metadata')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
