{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e58985eb-0de7-4131-b0b1-bf818eac896e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.pixi/envs/default/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import mlflow as mf \n",
    "import joblib\n",
    "import torch\n",
    "import transformers\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import ftzard.utils.mlflow as mf_utils\n",
    "\n",
    "\n",
    "from hydra import initialize, compose\n",
    "from warnings import filterwarnings\n",
    "\n",
    "import dagstermill as dgm\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd5cf634-dd6e-4115-a1c9-02de1107a0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../..'\n",
    "config_path = f'../../config/'\n",
    "config_name = 'config'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f679b0c-d97e-464f-a795-8641f1087e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(version_base=None, config_path=config_path):\n",
    "    cfg = compose(config_name=config_name)\n",
    "    tracking_uri, experiment_name = cfg.MLFLOW_TRACKING_URI, cfg.MLFLOW_EXPERIMENT_NAME\n",
    "    mlflow_model_name = cfg.MLFLOW_MODEL_NAME \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6641cd61-21f5-4436-99c9-4733ccfeb7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mlflow Experiment Name:  senetiment_analysis\n",
      "Mlflow Run Name:  sampling\n",
      "Path to Data:  ../../data/predictions.joblib\n"
     ]
    }
   ],
   "source": [
    "os.environ['MLFLOW_TRACKING_URI'] = tracking_uri\n",
    "run_name = 'sampling'\n",
    "data_path = f\"{base_path}/data/predictions.joblib\"\n",
    "print('Mlflow Experiment Name: ', experiment_name)\n",
    "print('Mlflow Run Name: ', run_name)\n",
    "print('Path to Data: ', data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10fab0fd-13f0-4d8c-8954-82d254d150a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_data = joblib.load(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06e028e6-197d-4c24-8488-81931e81af4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'predicted_labels', 'logits'])\n"
     ]
    }
   ],
   "source": [
    "print(predictions_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adc97503-00fd-44a0-a7a1-e245fc828a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 2) [-2.002 -1.101]\n"
     ]
    }
   ],
   "source": [
    "logits = predictions_data[\"logits\"]\n",
    "logits = np.array(logits)\n",
    "print(logits.shape, logits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2e1cf54-83f8-44de-8eba-55f940cb2b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax Logits: \n",
      " [[0.28880772 0.71119228]\n",
      " [0.90685284 0.09314716]\n",
      " [0.98351495 0.01648505]]\n",
      "Uncertainity Scores: \n",
      " [0.14440386 0.04657358 0.00824253]\n"
     ]
    }
   ],
   "source": [
    "def softmax(array):\n",
    "    exponents, result  = np.zeros(array.shape), np.zeros(array.shape)\n",
    "    for index in range(len(array)):\n",
    "        exponents[index] = np.exp(array[index])\n",
    "    for index in range(len(array)):\n",
    "        result[index] = exponents[index]/np.sum(exponents)\n",
    "\n",
    "    return result\n",
    "\n",
    "def least_confidence_sampling(array):\n",
    "    return (1 - np.max(array))/(len(array)/(len(array)-1))\n",
    "    \n",
    "        \n",
    "\n",
    "softmax_logits = np.array([softmax(elem) for elem in logits])\n",
    "print('Softmax Logits: \\n', softmax_logits[:3])\n",
    "\n",
    "\n",
    "uncertainity_scores = np.array([least_confidence_sampling(item) for item in softmax_logits])\n",
    "print('Uncertainity Scores: \\n', uncertainity_scores[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ba880c0-f378-45d1-b419-5dc1454f2639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of Uncertainity Scores:  [0.00014256779551441445, 0.24848677922905382]\n",
      "Maximum Uncertainity Score 0.5\n"
     ]
    }
   ],
   "source": [
    "range_of_uncertainity = [np.min(uncertainity_scores), np.max(uncertainity_scores)]\n",
    "print('Range of Uncertainity Scores: ', range_of_uncertainity)\n",
    "print('Maximum Uncertainity Score', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52c62911-4d0d-4696-afff-d8aa2eeda4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_uncertain_indices = np.where(uncertainity_scores>=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "99be0e5b-5554-46f4-8842-efd0190fd854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['label', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 86\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "top_uncertain_data = predictions_data[\"data\"].select(top_uncertain_indices[0])\n",
    "print(top_uncertain_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b67a441c-e93e-4dae-8617-097cd609e6c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 86\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgm.yield_result(top_uncertain_data, output_name=\"retraining_data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
