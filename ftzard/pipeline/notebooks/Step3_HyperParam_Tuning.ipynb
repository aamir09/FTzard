{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "785e2c3e-d2e9-4c2d-b76d-857ddacb7d3a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.pixi/envs/default/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import mlflow as mf\n",
    "import shutil\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    Trainer,\n",
    "    AutoModelForSequenceClassification,       \n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score\n",
    "import numpy as np\n",
    "from ftzard.utils.common import get_current_date_time\n",
    "from trl import SFTTrainer\n",
    "from hydra import initialize, compose\n",
    "import optuna\n",
    "import ftzard.utils.mlflow as mf_utils\n",
    "import joblib\n",
    "import dagstermill as dgm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a18f65cf-ebd7-468e-af95-43793a3993ad",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul  1 08:26:37 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.48.07    Driver Version: 515.48.07    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 40%   53C    P8     1W / 260W |     18MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 43%   64C    P8    39W / 260W |      8MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5424330-8d09-47c0-8057-c2a5e37ab54e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CUDA devices available: 2\n",
      "Device 0: NVIDIA GeForce RTX 2080 Ti\n",
      "Device 1: NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the number of available CUDA devices\n",
    "    num_devices = torch.cuda.device_count()\n",
    "    print(f\"Number of CUDA devices available: {num_devices}\")\n",
    "\n",
    "    # Print information about each device\n",
    "    for i in range(num_devices):\n",
    "        device_name = torch.cuda.get_device_name(i)\n",
    "        print(f\"Device {i}: {device_name}\")\n",
    "else:\n",
    "    print(\"CUDA is not available on this system.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "274cc7a8-ceac-4ef0-8917-0379c5d4eb32",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/app/ftzard/pipeline/notebooks'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11a9bfa7-fb08-47cc-bc23-661d6ad0fccf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symlink already created...\n"
     ]
    }
   ],
   "source": [
    "base_path = '/app/ftzard'\n",
    "config_path = f'{base_path}/config/'\n",
    "try:\n",
    "    os.symlink(config_path, \"config_link\")\n",
    "except Exception as e:\n",
    "    print(\"Symlink already created...\")\n",
    "data_path = f\"{base_path}/data/tokenized_dataset.joblib\"\n",
    "config_name = 'config'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "597bdc40-63ab-45a7-999c-ddb1197aece5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with initialize(version_base=None, config_path=\"config_link\"):\n",
    "    cfg = compose(config_name=config_name)\n",
    "    tracking_uri, experiment_name = cfg.MLFLOW.TRACKING.URI, cfg.MLFLOW.EXPERIMENT.NAME\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "756e94dd-e7fd-45ce-bb1e-6837ffc579ad",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Run Name:  HP-TUNING\n",
      "Data Path:  /app/ftzard/data/tokenized_dataset.joblib\n",
      "Mlflow Experiment Name:  senetiment_analysis\n",
      "Mlflow Run Name:  2024-07-01_8:26\n",
      "Model Name:  tiiuae/falcon-7b\n"
     ]
    }
   ],
   "source": [
    "os.environ['MLFLOW_TRACKING_URI'] = tracking_uri\n",
    "run_name = get_current_date_time()\n",
    "model_name = cfg.HUGGINGFACE.MODEL.NAME\n",
    "base_run_name = \"HP-TUNING\"\n",
    "max_len = 1024\n",
    "print(\"Base Run Name: \", base_run_name)\n",
    "print('Data Path: ', data_path)\n",
    "print('Mlflow Experiment Name: ', experiment_name)\n",
    "print('Mlflow Run Name: ', run_name)\n",
    "print('Model Name: ', model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dbe9a17-058d-4b42-adca-4e497dfb493f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "datasets = joblib.load(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89f2835f-75ae-4cd8-a3c5-aecf337e91fc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets = datasets[\"datasets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db92a5ca-8d18-44f8-a910-4dcae92a74ed",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e75de36a-aa05-4552-b482-940eb1ee9b8e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fbb4269-eac0-4b87-852a-28f31cc0a2f0",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards:   0%|                                                    | 0/2 [00:00<?, ?it/s]/app/.pixi/envs/default/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:14<00:00,  7.07s/it]\n",
      "Some weights of FalconForSequenceClassification were not initialized from the model checkpoint at tiiuae/falcon-7b and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FalconForSequenceClassification(\n",
      "  (transformer): FalconModel(\n",
      "    (word_embeddings): Embedding(65024, 4544)\n",
      "    (h): ModuleList(\n",
      "      (0-31): 32 x FalconDecoderLayer(\n",
      "        (self_attention): FalconAttention(\n",
      "          (rotary_emb): FalconRotaryEmbedding()\n",
      "          (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "          (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (mlp): FalconMLP(\n",
      "          (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "          (act): GELUActivation()\n",
      "          (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "        )\n",
      "        (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (score): Linear(in_features=4544, out_features=2, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=quant_config,\n",
    "    num_labels=2,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd47d2be-866a-4fcb-a3cf-8b5607382427",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FalconForSequenceClassification(\n",
      "  (transformer): FalconModel(\n",
      "    (word_embeddings): Embedding(65024, 4544)\n",
      "    (h): ModuleList(\n",
      "      (0-31): 32 x FalconDecoderLayer(\n",
      "        (self_attention): FalconAttention(\n",
      "          (rotary_emb): FalconRotaryEmbedding()\n",
      "          (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "          (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (mlp): FalconMLP(\n",
      "          (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "          (act): GELUActivation()\n",
      "          (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "        )\n",
      "        (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (score): Linear(in_features=4544, out_features=2, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = prepare_model_for_kbit_training(model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f9ed953-1ca8-4b47-8691-4e4eaaaa876a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_lora_model(model, config):\n",
    "    return get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78902d79-7af7-4058-80b7-1b7cd65bbe54",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {'balanced_accuracy' : balanced_accuracy_score(predictions, labels),'accuracy':accuracy_score(predictions,labels)}\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # Ensure label_weights is a tensor\n",
    "        if class_weights is not None:\n",
    "            self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n",
    "        else:\n",
    "            self.class_weights = None\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        # Extract labels and convert them to long type for cross_entropy\n",
    "        labels = inputs.pop(\"labels\").long()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        # Extract logits assuming they are directly outputted by the model\n",
    "        logits = outputs.get('logits')\n",
    "\n",
    "        # Compute custom loss with class weights for imbalanced data handling\n",
    "        if self.class_weights is not None:\n",
    "            loss = F.cross_entropy(logits, labels, weight=self.class_weights)\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7361b3a3-db93-4947-b009-925221398382",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-01 08:27:06,340] A new study created in memory with name: no-name-feec8c7c-3f0d-41da-9020-bd6022ec8d7d\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5602b68d-6bc5-4aa6-9ac3-e5a7915251a4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 14400\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1120\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 480\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbee106-e2eb-4d2c-9ac4-63248b6dd9b2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### I will train on a subset of data to capture the output using the select function in huggingace datset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0722a556-638b-4a78-8188-054b8ef1a1fe",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:alembic.runtime.migration:Context impl SQLiteImpl.\n",
      "INFO:alembic.runtime.migration:Will assume non-transactional DDL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided experiment name senetiment_analysis already exists, the run will be logged in this experiment.\n",
      "                                 \n",
      "Experiment Id:  1\n",
      "Run Id:  ff351744c39747a0ad96867671e49953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.pixi/envs/default/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 04:22, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.406359</td>\n",
       "      <td>0.824145</td>\n",
       "      <td>0.823214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.pixi/envs/default/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 01:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.pixi/envs/default/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "INFO:peft.tuners.tuners_utils:Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Id:  0a517780063642ecadd0fbeece580d28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.pixi/envs/default/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 04:30, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.476641</td>\n",
       "      <td>0.811426</td>\n",
       "      <td>0.794643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.pixi/envs/default/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 01:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.pixi/envs/default/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "INFO:peft.tuners.tuners_utils:Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Id:  d86ae004ad9b436ca757d8ee9af0b44a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.pixi/envs/default/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 05:10, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.782862</td>\n",
       "      <td>0.538034</td>\n",
       "      <td>0.533036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.pixi/envs/default/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 01:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.pixi/envs/default/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "INFO:peft.tuners.tuners_utils:Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Id:  acf3d09f0575420d8e6109223861b7cd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.pixi/envs/default/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 05:52, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.439007</td>\n",
       "      <td>0.815590</td>\n",
       "      <td>0.814286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.pixi/envs/default/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 01:40]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.pixi/envs/default/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    mf.end_run()\n",
    "artifact_path = \"mlartifacts\"\n",
    "experiment_id = mf_utils.create_experiment(exp_name=experiment_name)\n",
    "top_level_run_id = mf_utils.get_run_id_by_name(run_name=base_run_name, \n",
    "                                             experiment_ids=[experiment_id])\n",
    "\n",
    "### RUN HP_TUNING ###\n",
    "with mf.start_run(run_id = top_level_run_id, run_name=base_run_name, experiment_id=experiment_id):\n",
    "    base_run_id = mf_utils.get_run_id_by_name(run_name=run_name, \n",
    "                                                 experiment_ids=[experiment_id], nested=True)\n",
    "    print('Experiment Id: ', experiment_id)\n",
    "\n",
    "    ## RUN FROM get_current_date_time()\n",
    "    with mf.start_run(run_id = base_run_id, experiment_id=experiment_id,\n",
    "                        run_name=run_name, nested=True):\n",
    "        for i in range(1, 5):\n",
    "            trial = study.ask()\n",
    "            nested_run_name = f\"{run_name}_trial_{i}\"\n",
    "            run_id = mf_utils.get_run_id_by_name(run_name=nested_run_name, \n",
    "                                                 experiment_ids=[experiment_id],\n",
    "                                                nested = True)\n",
    "            print('Run Id: ', run_id)\n",
    "\n",
    "            ### HYPERPARAM RUN ###\n",
    "            if run_id:\n",
    "                mf.start_run(run_id=run_id, run_name=nested_run_name, experiment_id=experiment_id, nested=True)\n",
    "            else:\n",
    "                mf.start_run(run_name=nested_run_name, experiment_id=experiment_id, nested=True)\n",
    "    \n",
    "            ## CHOOSE HYPERAPARAMTERS ####\n",
    "    \n",
    "            rank = trial.suggest_categorical(\"rank\", [8,16,32,64])\n",
    "            lr = trial.suggest_float(\"lr\", 0.00006, 0.0004,)\n",
    "            batch_size = trial.suggest_categorical(\"batch_size\", [8,16,32,64])\n",
    "            weight_decay = trial.suggest_float(\"weight_decay\", 0.0005, 0.02)\n",
    "            lora_dropout = trial.suggest_float(\"lora_dropout\", 0.03, 0.06)\n",
    "            try:\n",
    "                mf.log_params(trial.params)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    \n",
    "            lora_config = LoraConfig(\n",
    "            r = rank, # the dimension of the low-rank matrices\n",
    "            lora_alpha = rank//2, # scaling factor for LoRA activations vs pre-trained weight activations\n",
    "            target_modules = [\n",
    "                \"query_key_value\",\n",
    "                \"dense\",\n",
    "                \"dense_h_to_4h\",\n",
    "                \"dense_4h_to_h\",\n",
    "                # \"score\"\n",
    "            ],\n",
    "            lora_dropout = lora_dropout, # dropout probability of the LoRA layers\n",
    "            bias = 'none', # wether to train bias weights, set to 'none' for attention layers\n",
    "            task_type = 'SEQ_CLS'\n",
    "            )\n",
    "    \n",
    "            lora_model = get_lora_model(model=model, config=lora_config)\n",
    "            lora_model.config.use_cache = False\n",
    "            lora_model.config.pretraining_tp = 1\n",
    "            lora_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "            \n",
    "            training_args = TrainingArguments(\n",
    "            output_dir = f'sentiment_classification_run_{i}',\n",
    "            learning_rate = lr,\n",
    "            per_device_train_batch_size = batch_size,\n",
    "            per_device_eval_batch_size = batch_size,\n",
    "            num_train_epochs = 1,\n",
    "            weight_decay = weight_decay,\n",
    "            evaluation_strategy = 'epoch',\n",
    "            save_strategy = 'epoch',\n",
    "            load_best_model_at_end = True\n",
    "            )\n",
    "        \n",
    "\n",
    "            trainer = CustomTrainer(\n",
    "            model = lora_model,\n",
    "            args = training_args,\n",
    "            train_dataset = datasets['train'].select(range(1000)),\n",
    "            eval_dataset = datasets['val'],\n",
    "            tokenizer = tokenizer,\n",
    "            data_collator = collate_fn,\n",
    "            compute_metrics = compute_metrics,\n",
    "            )\n",
    "    \n",
    "            result = trainer.train()\n",
    "            eval_res = trainer.evaluate()\n",
    "            study.tell(trial, eval_res['eval_accuracy'])\n",
    "            trainer.save_model(f'{base_path}/data/artifacts/{run_name}_run_{i}')\n",
    "            mf.log_artifacts(local_dir=f'{base_path}/data/artifacts/{run_name}_run_{i}')\n",
    "            mf.end_run()\n",
    "            shutil.rmtree(f'sentiment_classification_run_{i}', ignore_errors=True)\n",
    "            del lora_model\n",
    "            \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
