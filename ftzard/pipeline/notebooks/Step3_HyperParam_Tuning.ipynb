{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "785e2c3e-d2e9-4c2d-b76d-857ddacb7d3a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.pixi/envs/default/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import mlflow as mf\n",
    "import shutil\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    Trainer,\n",
    "    AutoModelForSequenceClassification,       \n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score\n",
    "import numpy as np\n",
    "from trl import SFTTrainer\n",
    "from hydra import initialize, compose\n",
    "import optuna\n",
    "import ftzard.utils.mlflow as mf_utils\n",
    "import joblib\n",
    "import dagstermill as dgm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a18f65cf-ebd7-468e-af95-43793a3993ad",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 28 16:03:42 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.48.07    Driver Version: 515.48.07    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 67%   77C    P8     4W / 260W |     18MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 73%   79C    P8    49W / 260W |      8MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5424330-8d09-47c0-8057-c2a5e37ab54e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CUDA devices available: 2\n",
      "Device 0: NVIDIA GeForce RTX 2080 Ti\n",
      "Device 1: NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the number of available CUDA devices\n",
    "    num_devices = torch.cuda.device_count()\n",
    "    print(f\"Number of CUDA devices available: {num_devices}\")\n",
    "\n",
    "    # Print information about each device\n",
    "    for i in range(num_devices):\n",
    "        device_name = torch.cuda.get_device_name(i)\n",
    "        print(f\"Device {i}: {device_name}\")\n",
    "else:\n",
    "    print(\"CUDA is not available on this system.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "274cc7a8-ceac-4ef0-8917-0379c5d4eb32",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/app/ftzard/pipeline/notebooks'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11a9bfa7-fb08-47cc-bc23-661d6ad0fccf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symlink already created...\n"
     ]
    }
   ],
   "source": [
    "base_path = '/app/ftzard'\n",
    "config_path = f'{base_path}/config/'\n",
    "try:\n",
    "    os.symlink(config_path, \"config_link\")\n",
    "except Exception as e:\n",
    "    print(\"Symlink already created...\")\n",
    "data_path = f\"{base_path}/data/tokenized_dataset.joblib\"\n",
    "config_name = 'config'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "597bdc40-63ab-45a7-999c-ddb1197aece5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with initialize(version_base=None, config_path=\"config_link\"):\n",
    "    cfg = compose(config_name=config_name)\n",
    "    tracking_uri, experiment_name = cfg.MLFLOW_TRACKING_URI, cfg.MLFLOW_EXPERIMENT_NAME\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "756e94dd-e7fd-45ce-bb1e-6837ffc579ad",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Path:  /app/ftzard/data/tokenized_dataset.joblib\n",
      "Mlflow Experiment Name:  senetiment_analysis\n",
      "Mlflow Run Name:  hyper_param_tuning\n",
      "Model Name:  tiiuae/falcon-7b\n"
     ]
    }
   ],
   "source": [
    "os.environ['MLFLOW_TRACKING_URI'] = tracking_uri\n",
    "run_name = 'hyper_param_tuning'\n",
    "model_name = cfg['model_name']\n",
    "max_len = 1024\n",
    "print('Data Path: ', data_path)\n",
    "print('Mlflow Experiment Name: ', experiment_name)\n",
    "print('Mlflow Run Name: ', run_name)\n",
    "print('Model Name: ', model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dbe9a17-058d-4b42-adca-4e497dfb493f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "datasets = joblib.load(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89f2835f-75ae-4cd8-a3c5-aecf337e91fc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets = datasets[\"datasets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db92a5ca-8d18-44f8-a910-4dcae92a74ed",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e75de36a-aa05-4552-b482-940eb1ee9b8e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fbb4269-eac0-4b87-852a-28f31cc0a2f0",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards:   0%|                                                    | 0/2 [00:00<?, ?it/s]/app/.pixi/envs/default/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:14<00:00,  7.32s/it]\n",
      "Some weights of FalconForSequenceClassification were not initialized from the model checkpoint at tiiuae/falcon-7b and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FalconForSequenceClassification(\n",
      "  (transformer): FalconModel(\n",
      "    (word_embeddings): Embedding(65024, 4544)\n",
      "    (h): ModuleList(\n",
      "      (0-31): 32 x FalconDecoderLayer(\n",
      "        (self_attention): FalconAttention(\n",
      "          (rotary_emb): FalconRotaryEmbedding()\n",
      "          (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "          (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (mlp): FalconMLP(\n",
      "          (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "          (act): GELUActivation()\n",
      "          (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "        )\n",
      "        (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (score): Linear(in_features=4544, out_features=2, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=quant_config,\n",
    "    num_labels=2,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd47d2be-866a-4fcb-a3cf-8b5607382427",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FalconForSequenceClassification(\n",
      "  (transformer): FalconModel(\n",
      "    (word_embeddings): Embedding(65024, 4544)\n",
      "    (h): ModuleList(\n",
      "      (0-31): 32 x FalconDecoderLayer(\n",
      "        (self_attention): FalconAttention(\n",
      "          (rotary_emb): FalconRotaryEmbedding()\n",
      "          (query_key_value): Linear4bit(in_features=4544, out_features=4672, bias=False)\n",
      "          (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
      "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (mlp): FalconMLP(\n",
      "          (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
      "          (act): GELUActivation()\n",
      "          (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
      "        )\n",
      "        (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (score): Linear(in_features=4544, out_features=2, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = prepare_model_for_kbit_training(model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f9ed953-1ca8-4b47-8691-4e4eaaaa876a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_lora_model(model, config):\n",
    "    return get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78902d79-7af7-4058-80b7-1b7cd65bbe54",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {'balanced_accuracy' : balanced_accuracy_score(predictions, labels),'accuracy':accuracy_score(predictions,labels)}\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # Ensure label_weights is a tensor\n",
    "        if class_weights is not None:\n",
    "            self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n",
    "        else:\n",
    "            self.class_weights = None\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        # Extract labels and convert them to long type for cross_entropy\n",
    "        labels = inputs.pop(\"labels\").long()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        # Extract logits assuming they are directly outputted by the model\n",
    "        logits = outputs.get('logits')\n",
    "\n",
    "        # Compute custom loss with class weights for imbalanced data handling\n",
    "        if self.class_weights is not None:\n",
    "            loss = F.cross_entropy(logits, labels, weight=self.class_weights)\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7361b3a3-db93-4947-b009-925221398382",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-28 16:04:01,306] A new study created in memory with name: no-name-8f53b284-b9ef-4166-80bf-33222ee7beaf\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5602b68d-6bc5-4aa6-9ac3-e5a7915251a4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 14400\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1120\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 480\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbee106-e2eb-4d2c-9ac4-63248b6dd9b2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### I will train on a subset of data to capture the output using the select function in huggingace datset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0722a556-638b-4a78-8188-054b8ef1a1fe",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided experiment name senetiment_analysis already exists, the run will be logged in this experiment.\n",
      "                                 \n",
      "Experiment Id:  1\n",
      "Run Id:  ad3bb09fd16a484eaa2b28b94aa4d263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.pixi/envs/default/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "2024/06/28 16:04:02 ERROR mlflow.utils.async_logging.async_logging_queue: Run Id ad3bb09fd16a484eaa2b28b94aa4d263: Failed to log run data: Exception: Changing param values is not allowed. Params were already logged='[{'key': 'per_device_train_batch_size', 'old_value': '64', 'new_value': '8'}, {'key': 'per_device_eval_batch_size', 'old_value': '64', 'new_value': '8'}, {'key': 'learning_rate', 'old_value': '0.000143964003631442', 'new_value': '0.0001816150646923802'}, {'key': 'weight_decay', 'old_value': '0.0018127487194426327', 'new_value': '0.0025094917033554663'}]' for run ID='ad3bb09fd16a484eaa2b28b94aa4d263'.\n",
      "2024/06/28 16:04:02 ERROR mlflow.utils.async_logging.async_logging_queue: Run Id ad3bb09fd16a484eaa2b28b94aa4d263: Failed to log run data: Exception: Changing param values is not allowed. Params were already logged='[{'key': 'logging_dir', 'old_value': 'sentiment_classification_run_1/runs/Jun28_15-49-14_8e802e6f43fc', 'new_value': 'sentiment_classification_run_1/runs/Jun28_16-04-02_8e802e6f43fc'}]' for run ID='ad3bb09fd16a484eaa2b28b94aa4d263'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 07:31, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.384444</td>\n",
       "      <td>0.836774</td>\n",
       "      <td>0.833036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.pixi/envs/default/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 02:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.pixi/envs/default/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Id:  583945e747d14a59aac76d58289e88f7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.pixi/envs/default/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "2024/06/28 16:13:45 ERROR mlflow.utils.async_logging.async_logging_queue: Run Id 583945e747d14a59aac76d58289e88f7: Failed to log run data: Exception: Changing param values is not allowed. Params were already logged='[{'key': 'per_device_train_batch_size', 'old_value': '64', 'new_value': '8'}, {'key': 'per_device_eval_batch_size', 'old_value': '64', 'new_value': '8'}, {'key': 'learning_rate', 'old_value': '0.00036132576750158005', 'new_value': '0.00026308290838911885'}, {'key': 'weight_decay', 'old_value': '0.007743633045510951', 'new_value': '0.016025928043566864'}]' for run ID='583945e747d14a59aac76d58289e88f7'.\n",
      "2024/06/28 16:13:45 ERROR mlflow.utils.async_logging.async_logging_queue: Run Id 583945e747d14a59aac76d58289e88f7: Failed to log run data: Exception: Changing param values is not allowed. Params were already logged='[{'key': 'logging_dir', 'old_value': 'sentiment_classification_run_2/runs/Jun28_15-56-09_8e802e6f43fc', 'new_value': 'sentiment_classification_run_2/runs/Jun28_16-13-45_8e802e6f43fc'}]' for run ID='583945e747d14a59aac76d58289e88f7'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 07:33, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.368138</td>\n",
       "      <td>0.844146</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.pixi/envs/default/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 02:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.pixi/envs/default/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Id:  f1c3dc78f81d45f590c9c3643f261dd1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.pixi/envs/default/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 07:56, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.377561</td>\n",
       "      <td>0.864453</td>\n",
       "      <td>0.864286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.pixi/envs/default/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 02:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.pixi/envs/default/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Id:  b77709b7f3364a1baa3b1d9a3965240d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.pixi/envs/default/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/32 03:29 < 00:52, 0.11 it/s, Epoch 0.78/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    mf.end_run()\n",
    "artifact_path = \"mlartifacts\"\n",
    "experiment_id = mf_utils.create_experiment(exp_name=experiment_name)\n",
    "base_run_id = mf_utils.get_run_id_by_name(run_name=run_name, \n",
    "                                             experiment_ids=[experiment_id])\n",
    "print('Experiment Id: ', experiment_id)\n",
    "with mf.start_run(run_id = base_run_id, experiment_id=experiment_id,\n",
    "                    run_name=run_name):\n",
    "    for i in range(1, 5):\n",
    "        trial = study.ask()\n",
    "        nested_run_name = f\"{run_name}_trial_{i}\"\n",
    "        run_id = mf_utils.get_run_id_by_name(run_name=nested_run_name, \n",
    "                                             experiment_ids=[experiment_id],\n",
    "                                            nested = True)\n",
    "        print('Run Id: ', run_id)\n",
    "        if run_id:\n",
    "            mf.start_run(run_id=run_id, run_name=nested_run_name, experiment_id=experiment_id, nested=True)\n",
    "        else:\n",
    "            mf.start_run(run_name=nested_run_name, experiment_id=experiment_id, nested=True)\n",
    "\n",
    "        ## CHOOSE HYPERAPARAMTERS ####\n",
    "\n",
    "        rank = trial.suggest_categorical(\"rank\", [8,16,32,64])\n",
    "        lr = trial.suggest_float(\"lr\", 0.00006, 0.0004,)\n",
    "        batch_size = trial.suggest_categorical(\"batch_size\", [8,16,32,64])\n",
    "        weight_decay = trial.suggest_float(\"weight_decay\", 0.0005, 0.02)\n",
    "        lora_dropout = trial.suggest_float(\"lora_dropout\", 0.03, 0.06)\n",
    "        try:\n",
    "            mf.log_params(trial.params)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "        lora_config = LoraConfig(\n",
    "        r = rank, # the dimension of the low-rank matrices\n",
    "        lora_alpha = rank//2, # scaling factor for LoRA activations vs pre-trained weight activations\n",
    "        target_modules = [\n",
    "            \"query_key_value\",\n",
    "            \"dense\",\n",
    "            \"dense_h_to_4h\",\n",
    "            \"dense_4h_to_h\",\n",
    "            # \"score\"\n",
    "        ],\n",
    "        lora_dropout = lora_dropout, # dropout probability of the LoRA layers\n",
    "        bias = 'none', # wether to train bias weights, set to 'none' for attention layers\n",
    "        task_type = 'SEQ_CLS'\n",
    "        )\n",
    "\n",
    "        lora_model = get_lora_model(model=model, config=lora_config)\n",
    "        lora_model.config.use_cache = False\n",
    "        lora_model.config.pretraining_tp = 1\n",
    "        lora_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "        output_dir = f'sentiment_classification_run_{i}',\n",
    "        learning_rate = lr,\n",
    "        per_device_train_batch_size = batch_size,\n",
    "        per_device_eval_batch_size = batch_size,\n",
    "        num_train_epochs = 1,\n",
    "        weight_decay = weight_decay,\n",
    "        evaluation_strategy = 'epoch',\n",
    "        save_strategy = 'epoch',\n",
    "        load_best_model_at_end = True\n",
    "        )\n",
    "        \n",
    "\n",
    "        trainer = CustomTrainer(\n",
    "        model = lora_model,\n",
    "        args = training_args,\n",
    "        train_dataset = datasets['train'].select(range(1000)),\n",
    "        eval_dataset = datasets['val'],\n",
    "        tokenizer = tokenizer,\n",
    "        data_collator = collate_fn,\n",
    "        compute_metrics = compute_metrics,\n",
    "        )\n",
    "\n",
    "        result = trainer.train()\n",
    "        eval_res = trainer.evaluate()\n",
    "        study.tell(trial, eval_res['eval_accuracy'])\n",
    "        trainer.save_model(f'{base_path}/data/artifacts/{run_name}_run_{i}')\n",
    "        mf.log_artifacts(local_dir=f'{base_path}/data/artifacts/{run_name}_run_{i}')\n",
    "        mf.end_run()\n",
    "        shutil.rmtree(f'sentiment_classification_run_{i}', ignore_errors=True)\n",
    "        del lora_model\n",
    "        \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
