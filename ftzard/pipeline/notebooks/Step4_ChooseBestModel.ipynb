{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b0e574c-fb51-4300-aa64-a240dc335d50",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!export PYTHONWARNINGS=\"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24b3d9f2-27fc-4c40-8e49-efeb4bac528f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.pixi/envs/default/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os \n",
    "import mlflow as mf \n",
    "import torch\n",
    "import joblib\n",
    "import transformers\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "from mlflow.models import infer_signature\n",
    "from torch.utils.data import DataLoader\n",
    "import ftzard.utils.mlflow as mf_utils\n",
    "from mlflow.models.signature import ModelSignature, infer_signature\n",
    "from mlflow.pyfunc import PythonModel\n",
    "from mlflow.types.schema import Schema, TensorSpec\n",
    "from hydra import initialize, compose\n",
    "from warnings import filterwarnings\n",
    "\n",
    "from transformers import (AutoModelForSequenceClassification, \n",
    "                            AutoTokenizer, BitsAndBytesConfig,\n",
    "                            DataCollatorWithPadding, pipeline)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from peft import get_peft_model, PeftConfig, PeftModel\n",
    "from ftzard.utils.dvc import get_current_date_time\n",
    "import dagstermill as dgm\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d839a52-5856-461e-bb22-270e138bf1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul  2 11:18:09 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.48.07    Driver Version: 515.48.07    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 41%   54C    P8     1W / 260W |     18MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 43%   64C    P8    38W / 260W |      8MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26373f9c-8402-421c-92b6-d673232d771a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symlink already created...\n"
     ]
    }
   ],
   "source": [
    "base_path = '/app/ftzard'\n",
    "config_path = f'{base_path}/config/'\n",
    "try:\n",
    "    os.symlink(config_path, \"config_link\")\n",
    "except Exception as e:\n",
    "    print(\"Symlink already created...\")\n",
    "config_name = 'config'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c690b41-969f-49f5-9b37-ea30f78845ca",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.0.1 available.\n"
     ]
    }
   ],
   "source": [
    "datasets = joblib.load(f\"{base_path}/data/tokenized_dataset.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767edd2b-89bd-43cc-8754-6662d3816d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(version_base=None, config_path=\"config_link\"):\n",
    "    cfg = compose(config_name=config_name)\n",
    "    tracking_uri, experiment_name = cfg.MLFLOW.TRACKING.URI, cfg.MLFLOW.EXPERIMENT.NAME\n",
    "    mlflow_model_name = cfg.MLFLOW.MODEL.NAME\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db6469a3-302e-4c96-9b11-9c699b6835c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Run Name:  CHOOSE-BEST-MODEL\n",
      "Mlflow Previous Run Name:  HP-TUNING\n",
      "Mlflow Experiment Name:  senetiment_analysis\n",
      "Mlflow Run Name:  2024-07-02_11:18\n",
      "Model Name:  tiiuae/falcon-7b\n"
     ]
    }
   ],
   "source": [
    "os.environ['MLFLOW_TRACKING_URI'] = tracking_uri\n",
    "base_run_name = \"CHOOSE-BEST-MODEL\"\n",
    "run_name = get_current_date_time()\n",
    "previous_run_name = 'HP-TUNING'\n",
    "model_name = cfg.HUGGINGFACE.MODEL.NAME\n",
    "\n",
    "print(\"Base Run Name: \", base_run_name)\n",
    "print('Mlflow Previous Run Name: ', previous_run_name)\n",
    "print('Mlflow Experiment Name: ', experiment_name)\n",
    "print('Mlflow Run Name: ', run_name)\n",
    "print('Model Name: ', model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bee91576-c200-40e4-9bb2-8fcb7c5a6ec6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:alembic.runtime.migration:Context impl SQLiteImpl.\n",
      "INFO:alembic.runtime.migration:Will assume non-transactional DDL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided experiment name senetiment_analysis already exists, the run will be logged in this experiment.\n",
      "                                 \n",
      "The Previous Run Id is:  254a177528514030a9a79e93926b2035\n"
     ]
    }
   ],
   "source": [
    "experiment_id = mf_utils.create_experiment(exp_name=experiment_name)\n",
    "previous_run_id = mf_utils.get_run_id_by_name(run_name=previous_run_name, \n",
    "                                             experiment_ids=[experiment_id],\n",
    "                                            nested = True)\n",
    "print('The Previous Run Id is: ', previous_run_id)\n",
    "if not previous_run_id:\n",
    "    raise IOError(\"Cannot find previous run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d465571e-568a-49e1-a88d-1ad251a946fc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Previous Run ID: 254a177528514030a9a79e93926b2035\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Previous Run ID: {previous_run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07ee896a-f5da-44ad-83eb-19e8dba9099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = mf.MlflowClient()\n",
    "base_child_runs =  client.search_runs(experiment_id, \n",
    "            filter_string=f\"tags.mlflow.parentRunId='{previous_run_id}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0dd76c3-202e-4596-a462-3eebb2c5e9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_child_runs = sorted(base_child_runs, key = lambda x: -x.info.start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffd63ca5-f41b-4005-87b1-3735c50800ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest Run: <Run: data=<RunData: metrics={}, params={}, tags={'mlflow.parentRunId': '254a177528514030a9a79e93926b2035',\n",
      " 'mlflow.runName': '2024-07-01_8:26',\n",
      " 'mlflow.source.name': '/app/.pixi/envs/default/lib/python3.11/site-packages/ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'root'}>, info=<RunInfo: artifact_uri='/app/ftzard/pipeline/notebooks/mlruns/1/9953da46234843f1a475e042a89a9b2c/artifacts', end_time=1719824002015, experiment_id='1', lifecycle_stage='active', run_id='9953da46234843f1a475e042a89a9b2c', run_name='2024-07-01_8:26', run_uuid='9953da46234843f1a475e042a89a9b2c', start_time=1719822426789, status='FINISHED', user_id='root'>, inputs=<RunInputs: dataset_inputs=[]>>\n"
     ]
    }
   ],
   "source": [
    "print('Latest Run:', base_child_runs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42c3360c-a049-46b2-8da3-1b4659af5dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_previous_child_run_id = base_child_runs[0].info.run_id\n",
    "child_runs =  client.search_runs(experiment_id, \n",
    "            filter_string=f\"tags.mlflow.parentRunId='{latest_previous_child_run_id}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85f41f6d-80cc-4eb1-b193-c1a5214e70a8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "child_runs.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9450a41c-f16d-4cdd-9b42-c3574dec9576",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets = datasets[\"datasets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86844eee-4d2a-43e7-a177-dfe0e8bcbb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['label', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 480\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(datasets['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c68d043-c436-4727-b9ee-70ca16e4be94",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:  2024-07-01_8:26_trial_4 | Id:  acf3d09f0575420d8e6109223861b7cd | Accuracy:  0.814 | Train Loss:  0.7663 | Eval Loss:  0.439 | Delta:  0.33\n",
      "Name:  2024-07-01_8:26_trial_3 | Id:  d86ae004ad9b436ca757d8ee9af0b44a | Accuracy:  0.533 | Train Loss:  1.5018 | Eval Loss:  0.7829 | Delta:  0.72\n",
      "Name:  2024-07-01_8:26_trial_2 | Id:  0a517780063642ecadd0fbeece580d28 | Accuracy:  0.795 | Train Loss:  0.8481 | Eval Loss:  0.4766 | Delta:  0.37\n",
      "Name:  2024-07-01_8:26_trial_1 | Id:  ff351744c39747a0ad96867671e49953 | Accuracy:  0.823 | Train Loss:  0.7326 | Eval Loss:  0.4064 | Delta:  0.33\n"
     ]
    }
   ],
   "source": [
    "for child in child_runs:\n",
    "    print('Name: ', child.info.run_name, '| Id: ', child.info.run_id, \n",
    "          \"| Accuracy: \", np.round(child.data.metrics[\"eval_accuracy\"], 3),\n",
    "         \"| Train Loss: \", np.round(child.data.metrics[\"train_loss\"], 4),\n",
    "         \"| Eval Loss: \", np.round(child.data.metrics[\"eval_loss\"], 4),\n",
    "         \"| Delta: \", np.round(np.round(child.data.metrics[\"train_loss\"], 4)\n",
    "                               - np.round(child.data.metrics[\"eval_loss\"], 4), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbe6423e-6ebc-4d4f-a362-7db3ba56553b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_run = None\n",
    "max_acc = -1000000000\n",
    "for child in child_runs:\n",
    "    if child.data.metrics[\"eval_accuracy\"]>max_acc:\n",
    "        best_run = child\n",
    "        max_acc = child.data.metrics[\"eval_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6905a39c-a3a8-4bfb-b35a-237b751ec60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Run: data=<RunData: metrics={'epoch': 1.0,\n",
      " 'eval_accuracy': 0.8232142857142857,\n",
      " 'eval_balanced_accuracy': 0.8241445474896067,\n",
      " 'eval_loss': 0.4063585102558136,\n",
      " 'eval_runtime': 76.5358,\n",
      " 'eval_samples_per_second': 14.634,\n",
      " 'eval_steps_per_second': 0.915,\n",
      " 'total_flos': 1403618202316800.0,\n",
      " 'train_loss': 0.7325710114978609,\n",
      " 'train_runtime': 266.3046,\n",
      " 'train_samples_per_second': 3.755,\n",
      " 'train_steps_per_second': 0.237}, params={'_name_or_path': 'tiiuae/falcon-7b',\n",
      " 'accelerator_config': \"{'split_batches': False, 'dispatch_batches': None, \"\n",
      "                       \"'even_batches': True, 'use_seedable_sampler': True, \"\n",
      "                       \"'non_blocking': False, 'gradient_accumulation_kwargs': \"\n",
      "                       'None}',\n",
      " 'activation': 'gelu',\n",
      " 'adafactor': 'False',\n",
      " 'adam_beta1': '0.9',\n",
      " 'adam_beta2': '0.999',\n",
      " 'adam_epsilon': '1e-08',\n",
      " 'add_cross_attention': 'False',\n",
      " 'alibi': 'False',\n",
      " 'apply_residual_connection_post_layernorm': 'False',\n",
      " 'architectures': \"['FalconForCausalLM']\",\n",
      " 'attention_dropout': '0.0',\n",
      " 'auto_find_batch_size': 'False',\n",
      " 'auto_map': \"{'AutoConfig': \"\n",
      "             \"'tiiuae/falcon-7b--configuration_falcon.FalconConfig', \"\n",
      "             \"'AutoModel': 'tiiuae/falcon-7b--modeling_falcon.FalconModel', \"\n",
      "             \"'AutoModelForSequenceClassification': \"\n",
      "             \"'tiiuae/falcon-7b--modeling_falcon.FalconForSequenceClassification', \"\n",
      "             \"'AutoModelForTokenClassification': \"\n",
      "             \"'tiiuae/falcon-7b--modeling_falcon.FalconForTokenClassification', \"\n",
      "             \"'AutoModelForQuestionAnswering': \"\n",
      "             \"'tiiuae/falcon-7b--modeling_falcon.FalconForQuestionAnswering', \"\n",
      "             \"'AutoModelForCausalLM': \"\n",
      "             \"'tiiuae/falcon-7b--modeling_falcon.FalconForCausalLM'}\",\n",
      " 'bad_words_ids': 'None',\n",
      " 'batch_eval_metrics': 'False',\n",
      " 'batch_size': '16',\n",
      " 'begin_suppress_tokens': 'None',\n",
      " 'bf16': 'False',\n",
      " 'bf16_full_eval': 'False',\n",
      " 'bias': 'False',\n",
      " 'bos_token_id': '11',\n",
      " 'chunk_size_feed_forward': '0',\n",
      " 'cross_attention_hidden_size': 'None',\n",
      " 'data_seed': 'None',\n",
      " 'dataloader_drop_last': 'False',\n",
      " 'dataloader_num_workers': '0',\n",
      " 'dataloader_persistent_workers': 'False',\n",
      " 'dataloader_pin_memory': 'True',\n",
      " 'dataloader_prefetch_factor': 'None',\n",
      " 'ddp_backend': 'None',\n",
      " 'ddp_broadcast_buffers': 'None',\n",
      " 'ddp_bucket_cap_mb': 'None',\n",
      " 'ddp_find_unused_parameters': 'None',\n",
      " 'ddp_timeout': '1800',\n",
      " 'debug': '[]',\n",
      " 'decoder_start_token_id': 'None',\n",
      " 'deepspeed': 'None',\n",
      " 'disable_tqdm': 'False',\n",
      " 'dispatch_batches': 'None',\n",
      " 'diversity_penalty': '0.0',\n",
      " 'do_eval': 'True',\n",
      " 'do_predict': 'False',\n",
      " 'do_sample': 'False',\n",
      " 'do_train': 'False',\n",
      " 'early_stopping': 'False',\n",
      " 'encoder_no_repeat_ngram_size': '0',\n",
      " 'eos_token_id': '11',\n",
      " 'eval_accumulation_steps': 'None',\n",
      " 'eval_delay': '0',\n",
      " 'eval_do_concat_batches': 'True',\n",
      " 'eval_steps': 'None',\n",
      " 'eval_strategy': 'epoch',\n",
      " 'evaluation_strategy': 'epoch',\n",
      " 'exponential_decay_length_penalty': 'None',\n",
      " 'ffn_hidden_size': '18176',\n",
      " 'finetuning_task': 'None',\n",
      " 'forced_bos_token_id': 'None',\n",
      " 'forced_eos_token_id': 'None',\n",
      " 'fp16': 'False',\n",
      " 'fp16_backend': 'auto',\n",
      " 'fp16_full_eval': 'False',\n",
      " 'fp16_opt_level': 'O1',\n",
      " 'fsdp': '[]',\n",
      " 'fsdp_config': \"{'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, \"\n",
      "                \"'xla_fsdp_grad_ckpt': False}\",\n",
      " 'fsdp_min_num_params': '0',\n",
      " 'fsdp_transformer_layer_cls_to_wrap': 'None',\n",
      " 'full_determinism': 'False',\n",
      " 'gradient_accumulation_steps': '1',\n",
      " 'gradient_checkpointing': 'False',\n",
      " 'gradient_checkpointing_kwargs': 'None',\n",
      " 'greater_is_better': 'False',\n",
      " 'group_by_length': 'False',\n",
      " 'half_precision_backend': 'auto',\n",
      " 'hidden_dropout': '0.0',\n",
      " 'hidden_size': '4544',\n",
      " 'hub_always_push': 'False',\n",
      " 'hub_model_id': 'None',\n",
      " 'hub_private_repo': 'False',\n",
      " 'hub_strategy': 'every_save',\n",
      " 'hub_token': '<HUB_TOKEN>',\n",
      " 'id2label': \"{0: 'LABEL_0', 1: 'LABEL_1'}\",\n",
      " 'ignore_data_skip': 'False',\n",
      " 'include_inputs_for_metrics': 'False',\n",
      " 'include_num_input_tokens_seen': 'False',\n",
      " 'include_tokens_per_second': 'False',\n",
      " 'initializer_range': '0.02',\n",
      " 'is_decoder': 'False',\n",
      " 'is_encoder_decoder': 'False',\n",
      " 'jit_mode_eval': 'False',\n",
      " 'label2id': \"{'LABEL_0': 0, 'LABEL_1': 1}\",\n",
      " 'label_names': 'None',\n",
      " 'label_smoothing_factor': '0.0',\n",
      " 'layer_norm_epsilon': '1e-05',\n",
      " 'learning_rate': '0.00011593253958922218',\n",
      " 'length_column_name': 'length',\n",
      " 'length_penalty': '1.0',\n",
      " 'load_best_model_at_end': 'True',\n",
      " 'local_rank': '0',\n",
      " 'log_level': 'passive',\n",
      " 'log_level_replica': 'warning',\n",
      " 'log_on_each_node': 'True',\n",
      " 'logging_dir': 'sentiment_classification_run_1/runs/Jul01_08-27-07_8e802e6f43fc',\n",
      " 'logging_first_step': 'False',\n",
      " 'logging_nan_inf_filter': 'True',\n",
      " 'logging_steps': '500',\n",
      " 'logging_strategy': 'steps',\n",
      " 'lora_dropout': '0.05187051351110231',\n",
      " 'lr': '0.00011593253958922218',\n",
      " 'lr_scheduler_kwargs': '{}',\n",
      " 'lr_scheduler_type': 'linear',\n",
      " 'max_grad_norm': '1.0',\n",
      " 'max_length': '20',\n",
      " 'max_position_embeddings': '2048',\n",
      " 'max_steps': '-1',\n",
      " 'metric_for_best_model': 'loss',\n",
      " 'min_length': '0',\n",
      " 'model_type': 'falcon',\n",
      " 'mp_parameters': '',\n",
      " 'multi_query': 'True',\n",
      " 'neftune_noise_alpha': 'None',\n",
      " 'new_decoder_architecture': 'False',\n",
      " 'no_cuda': 'False',\n",
      " 'no_repeat_ngram_size': '0',\n",
      " 'num_attention_heads': '71',\n",
      " 'num_beam_groups': '1',\n",
      " 'num_beams': '1',\n",
      " 'num_hidden_layers': '32',\n",
      " 'num_kv_heads': '71',\n",
      " 'num_ln_in_parallel_attn': 'None',\n",
      " 'num_return_sequences': '1',\n",
      " 'num_train_epochs': '1',\n",
      " 'optim': 'adamw_torch',\n",
      " 'optim_args': 'None',\n",
      " 'optim_target_modules': 'None',\n",
      " 'output_attentions': 'False',\n",
      " 'output_dir': 'sentiment_classification_run_1',\n",
      " 'output_hidden_states': 'False',\n",
      " 'output_scores': 'False',\n",
      " 'overwrite_output_dir': 'False',\n",
      " 'pad_token_id': '11',\n",
      " 'parallel_attn': 'True',\n",
      " 'past_index': '-1',\n",
      " 'per_device_eval_batch_size': '16',\n",
      " 'per_device_train_batch_size': '16',\n",
      " 'per_gpu_eval_batch_size': 'None',\n",
      " 'per_gpu_train_batch_size': 'None',\n",
      " 'prediction_loss_only': 'False',\n",
      " 'prefix': 'None',\n",
      " 'pretraining_tp': '1',\n",
      " 'problem_type': 'None',\n",
      " 'pruned_heads': '{}',\n",
      " 'push_to_hub': 'False',\n",
      " 'push_to_hub_model_id': 'None',\n",
      " 'push_to_hub_organization': 'None',\n",
      " 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>',\n",
      " 'quantization_config': \"{'quant_method': <QuantizationMethod.BITS_AND_BYTES: \"\n",
      "                        \"'bitsandbytes'>, '_load_in_8bit': False, \"\n",
      "                        \"'_load_in_4bit': True, 'llm_int8_threshold': 6.0, \"\n",
      "                        \"'llm_int8_skip_modules': None, \"\n",
      "                        \"'llm_int8_enable_fp32_cpu_offload': False, \"\n",
      "                        \"'llm_int8_has_fp16_weight': False, \"\n",
      "                        \"'bnb_4bit_quant_type': 'nf4', \"\n",
      "                        \"'bnb_4bit_use_double_quant': False, \"\n",
      "                        \"'bnb_4bit_compute_dtype': 'float16', \"\n",
      "                        \"'bnb_4bit_quant_storage': 'uint8', 'load_in_4bit': \"\n",
      "                        \"True, 'load_in_8bit': False}\",\n",
      " 'rank': '32',\n",
      " 'ray_scope': 'last',\n",
      " 'remove_invalid_values': 'False',\n",
      " 'remove_unused_columns': 'True',\n",
      " 'repetition_penalty': '1.0',\n",
      " 'report_to': \"['mlflow']\",\n",
      " 'restore_callback_states_from_checkpoint': 'False',\n",
      " 'resume_from_checkpoint': 'None',\n",
      " 'return_dict': 'True',\n",
      " 'return_dict_in_generate': 'False',\n",
      " 'rope_scaling': 'None',\n",
      " 'rope_theta': '10000.0',\n",
      " 'run_name': 'sentiment_classification_run_1',\n",
      " 'save_on_each_node': 'False',\n",
      " 'save_only_model': 'False',\n",
      " 'save_safetensors': 'True',\n",
      " 'save_steps': '500',\n",
      " 'save_strategy': 'epoch',\n",
      " 'save_total_limit': 'None',\n",
      " 'seed': '42',\n",
      " 'sep_token_id': 'None',\n",
      " 'skip_memory_metrics': 'True',\n",
      " 'split_batches': 'None',\n",
      " 'suppress_tokens': 'None',\n",
      " 'task_specific_params': 'None',\n",
      " 'temperature': '1.0',\n",
      " 'tf32': 'None',\n",
      " 'tf_legacy_loss': 'False',\n",
      " 'tie_encoder_decoder': 'False',\n",
      " 'tie_word_embeddings': 'True',\n",
      " 'tokenizer_class': 'None',\n",
      " 'top_k': '50',\n",
      " 'top_p': '1.0',\n",
      " 'torch_compile': 'False',\n",
      " 'torch_compile_backend': 'None',\n",
      " 'torch_compile_mode': 'None',\n",
      " 'torch_dtype': 'bfloat16',\n",
      " 'torchdynamo': 'None',\n",
      " 'torchscript': 'False',\n",
      " 'tpu_metrics_debug': 'False',\n",
      " 'tpu_num_cores': 'None',\n",
      " 'transformers_version': '4.41.2',\n",
      " 'typical_p': '1.0',\n",
      " 'use_bfloat16': 'False',\n",
      " 'use_cache': 'False',\n",
      " 'use_cpu': 'False',\n",
      " 'use_ipex': 'False',\n",
      " 'use_legacy_prediction_loop': 'False',\n",
      " 'use_mps_device': 'False',\n",
      " 'vocab_size': '65024',\n",
      " 'warmup_ratio': '0.0',\n",
      " 'warmup_steps': '0',\n",
      " 'weight_decay': '0.009657724034743654'}, tags={'mlflow.parentRunId': '9953da46234843f1a475e042a89a9b2c',\n",
      " 'mlflow.runName': '2024-07-01_8:26_trial_1',\n",
      " 'mlflow.source.name': '/app/.pixi/envs/default/lib/python3.11/site-packages/ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'root'}>, info=<RunInfo: artifact_uri='/app/ftzard/pipeline/notebooks/mlruns/1/ff351744c39747a0ad96867671e49953/artifacts', end_time=1719822771715, experiment_id='1', lifecycle_stage='active', run_id='ff351744c39747a0ad96867671e49953', run_name='2024-07-01_8:26_trial_1', run_uuid='ff351744c39747a0ad96867671e49953', start_time=1719822426821, status='FINISHED', user_id='root'>, inputs=<RunInputs: dataset_inputs=[]>>\n"
     ]
    }
   ],
   "source": [
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51c3e1dd-0db8-46dd-9d71-2ad30108e22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aritifacts Path:  /app/ftzard/pipeline/notebooks/mlruns/1/ff351744c39747a0ad96867671e49953/artifacts\n"
     ]
    }
   ],
   "source": [
    "artifact_path = best_run.info.artifact_uri\n",
    "print('Aritifacts Path: ', artifact_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ea4867d-6e74-4415-b308-90f5566d90ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers_modules.tiiuae.falcon-7b.898df1396f35e447d5fe44e0a3ccaaaa69f30d36.configuration_falcon:\n",
      "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
      "\n",
      "Loading checkpoint shards: 100%|████████████████████████████████████████████| 2/2 [00:15<00:00,  7.62s/it]\n",
      "Some weights of FalconForSequenceClassification were not initialized from the model checkpoint at tiiuae/falcon-7b and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Loading fine-tuned model from Hugging Face\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "config = PeftConfig.from_pretrained(artifact_path)\n",
    "peft_base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    return_dict=True,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"cuda:1\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(peft_base_model, artifact_path)\n",
    "\n",
    "peft_tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "peft_tokenizer.pad_token = peft_tokenizer.eos_token\n",
    "peft_model.config.pad_token_id = peft_tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19a0d86c-6fa7-4029-89d4-f0843bdabd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEFT CONFIG:  LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='tiiuae/falcon-7b', revision=None, task_type='SEQ_CLS', inference_mode=True, r=32, target_modules={'dense_4h_to_h', 'query_key_value', 'dense_h_to_4h', 'dense'}, lora_alpha=16, lora_dropout=0.05187051351110231, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=['classifier', 'score'], init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None)\n"
     ]
    }
   ],
   "source": [
    "print(\"PEFT CONFIG: \", config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e01f6301-92f0-45e5-9a0d-2b9541741bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device of PEFT MODEL:  cuda:1\n",
      "Getting predictions from best model....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 15/15 [00:08<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching true labels from dataset....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 438.15it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "Preparing Data For Evaluation\n",
    "'''\n",
    "eval_dataloader = DataLoader(\n",
    "    datasets[\"test\"],\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    collate_fn=DataCollatorWithPadding(tokenizer=peft_tokenizer),\n",
    ")\n",
    "\n",
    "device = peft_model.device\n",
    "\n",
    "print(\"Device of PEFT MODEL: \", device)\n",
    "\n",
    "def get_predictions(batch):\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    # token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = peft_model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        predicted_labels = torch.argmax(logits, dim=-1) # Move predicted_labels to the same device\n",
    "\n",
    "    return predicted_labels.cpu().numpy()\n",
    "\n",
    "print('Getting predictions from best model....')\n",
    "\n",
    "all_predictions = []\n",
    "for batch in tqdm(eval_dataloader):\n",
    "    predictions = get_predictions(batch)\n",
    "    all_predictions.extend(predictions)\n",
    "\n",
    "print('Fetching true labels from dataset....')\n",
    "true = []\n",
    "for batch in tqdm(eval_dataloader):\n",
    "    true.extend(batch['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2865f958-ce27-46ec-a999-225741037a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Classification Report         \n",
      "-----------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.80      0.85       240\n",
      "           1       0.82      0.92      0.87       240\n",
      "\n",
      "    accuracy                           0.86       480\n",
      "   macro avg       0.87      0.86      0.86       480\n",
      "weighted avg       0.87      0.86      0.86       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('                  Classification Report         ')\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(classification_report(true, all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0008d0d-fcaa-46a6-872f-e34e6f978bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/07/02 11:28:41 INFO mlflow.transformers: Overriding save_pretrained to False for PEFT models, following the Transformers behavior. The PEFT adaptor and config will be saved, but the base model weights will not and reference to the HuggingFace Hub repository will be logged instead.\n",
      "2024/07/02 11:28:41 INFO mlflow.transformers: Skipping saving pretrained model weights to disk as the save_pretrained is set to False. The reference to HuggingFace Hub repository tiiuae/falcon-7b will be logged instead.\n",
      "2024/07/02 11:28:41 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Registered model 'FalconSentiAnalysis' already exists. Creating a new version of this model...\n",
      "Created version '4' of model 'FalconSentiAnalysis'.\n"
     ]
    }
   ],
   "source": [
    "with mf.start_run(run_id=previous_run_id):\n",
    "    with mf.start_run(run_id=latest_previous_child_run_id, nested=True):\n",
    "        result = mf.transformers.log_model(\n",
    "            registered_model_name = mlflow_model_name,\n",
    "            transformers_model = {\"model\":peft_model, \"tokenizer\":peft_tokenizer},\n",
    "            artifact_path=\"\",\n",
    "            pip_requirements=[\"--no-deps\"],\n",
    "            task = \"text-classification\",\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1fcc439b-289a-49cd-b6ab-f13babf0aac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change Alias in the UI\n",
    "client.set_registered_model_alias(mlflow_model_name, \"champion\", 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
